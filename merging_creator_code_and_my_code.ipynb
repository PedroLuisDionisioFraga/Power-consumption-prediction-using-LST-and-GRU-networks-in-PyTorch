{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gasto_energia.csv']\n"
     ]
    }
   ],
   "source": [
    "# Define data root directory\n",
    "data_dir = \"./data/After Filters\"\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_sliding_window(data, window_size, inputs_cols_indices, label_col_index):\n",
    "    \"\"\"\n",
    "    data: numpy array including data\n",
    "    window_size: size of window\n",
    "    inputs_cols_indices: col indices to include\n",
    "    \"\"\"\n",
    "\n",
    "    # (# instances created by movement, seq_len (timestamps), # features (input_len))\n",
    "    inputs = np.zeros((len(data) - window_size, window_size, len(inputs_cols_indices)))\n",
    "    labels = np.zeros(len(data) - window_size)\n",
    "\n",
    "    for i in range(window_size, len(data)):\n",
    "        inputs[i - window_size] = data[i - window_size : i, inputs_cols_indices]\n",
    "        labels[i - window_size] = data[i, label_col_index]\n",
    "    inputs = inputs.reshape(-1, window_size, len(inputs_cols_indices))\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    print(inputs.shape, labels.shape)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47667ab635914200b038d4b7a95f22d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gasto_energia.csv ...\n",
      "       Datetime         MWh\n",
      "0    1999-01-01  1097488.80\n",
      "1    1999-01-02  1188379.20\n",
      "2    1999-01-03  1172990.40\n",
      "3    1999-01-04  1522963.20\n",
      "4    1999-01-05  1539184.80\n",
      "...         ...         ...\n",
      "8761 2022-12-27  2790594.67\n",
      "8762 2022-12-28  2649072.05\n",
      "8763 2022-12-29  2556168.02\n",
      "8764 2022-12-30  2573376.26\n",
      "8765 2022-12-31  2457169.96\n",
      "\n",
      "[8766 rows x 2 columns]\n",
      "(8676, 90, 5) (8676, 1)\n"
     ]
    }
   ],
   "source": [
    "label_col_index = 0  # consumption as label to predict\n",
    "inputs_cols_indices = range(5)  # use (consumption, hour, dayofweek, month, dayofyear) columns as features\n",
    "\n",
    "# Define window_size period and split inputs/labels\n",
    "window_size = 90\n",
    "\n",
    "# The scaler objects will be stored in this dictionary so that our output test data from the model can be re-scaled during evaluation\n",
    "label_scalers = {}\n",
    "\n",
    "train_x = []\n",
    "test_x = {}\n",
    "test_y = {}\n",
    "\n",
    "# Skipping the files we're not using\n",
    "processing_files = [file for file in os.listdir(data_dir) if os.path.splitext(file)[1] == \".csv\"]\n",
    "\n",
    "num_files_for_dataset = 5\n",
    "\n",
    "for file in tqdm_notebook(processing_files[:num_files_for_dataset]):\n",
    "  print(f\"Processing {file} ...\")\n",
    "  # Store csv file in a Pandas DataFrame\n",
    "  df = pd.read_csv(os.path.join(data_dir, file), parse_dates=[\"Datetime\"])\n",
    "  print(df)\n",
    "\n",
    "  # Processing the time data into suitable input formats\n",
    "  df[\"hour\"] = df.apply(lambda x: x[\"Datetime\"].hour, axis=1)\n",
    "  df[\"dayofweek\"] = df.apply(lambda x: x[\"Datetime\"].dayofweek, axis=1)\n",
    "  df[\"month\"] = df.apply(lambda x: x[\"Datetime\"].month, axis=1)\n",
    "  df[\"dayofyear\"] = df.apply(lambda x: x[\"Datetime\"].dayofyear, axis=1)\n",
    "  df = df.sort_values(\"Datetime\").drop(\"Datetime\", axis=1)\n",
    "  # df = df.drop(\"Time\", axis=1)\n",
    "\n",
    "  # Scaling the input data\n",
    "  sc = MinMaxScaler()\n",
    "  label_sc = MinMaxScaler()\n",
    "  data = sc.fit_transform(df.values)\n",
    "\n",
    "  # Obtaining the scaler for the labels(usage data) so that output can be\n",
    "  # re-scaled to actual value during evaluation\n",
    "  label_sc.fit(df.iloc[:, label_col_index].values.reshape(-1, 1))\n",
    "  label_scalers[file] = label_sc\n",
    "\n",
    "  # Move the window\n",
    "  inputs, labels = move_sliding_window(\n",
    "    data,\n",
    "    window_size,\n",
    "    inputs_cols_indices=inputs_cols_indices,\n",
    "    label_col_index=label_col_index,\n",
    "  )\n",
    "\n",
    "  # CONCAT created instances from all .csv files.\n",
    "  # Split data into train/test portions and combining all data from different files into a single array\n",
    "  test_portion = int(0.1 * len(inputs))\n",
    "  if len(train_x) == 0:  # first iteration\n",
    "    train_x = inputs[:-test_portion]\n",
    "    train_y = labels[:-test_portion]\n",
    "  else:\n",
    "    train_x = np.concatenate((train_x, inputs[:-test_portion]))\n",
    "    train_y = np.concatenate((train_y, labels[:-test_portion]))\n",
    "  test_x[file] = inputs[-test_portion:]\n",
    "  test_y[file] = labels[-test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "\n",
    "# Drop the last incomplete batch\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: (7809, 90, 5), Batch Size: 1024, # of iterations per epoch: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Size: {train_x.shape}, Batch Size: {batch_size}, # of iterations per epoch: {int(train_x.shape[0]/batch_size)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release some memory\n",
    "del train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPU is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "    super(GRUNet, self).__init__()\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.gru = nn.GRU(\n",
    "      input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob\n",
    "    )\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x, h):\n",
    "    out, h = self.gru(x, h)\n",
    "    # print(out[:, -1].shape, h.shape)\n",
    "    # select hidden state of last timestamp (t=90) (1024, 256)\n",
    "    out = self.fc(self.relu(out[:, -1]))  # out[:, -1, :]\n",
    "    # print(out.shape) # (1024, 1)\n",
    "    return out, h\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    # Initialze h_0 with zeros\n",
    "    weight = next(self.parameters()).data\n",
    "    hidden = (\n",
    "        weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "    )\n",
    "    return hidden\n",
    "\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "    super(LSTMNet, self).__init__()\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x, h):\n",
    "    out, h = self.lstm(x, h)\n",
    "    out = self.fc(self.relu(out[:, -1]))\n",
    "    return out, h\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    weight = next(self.parameters()).data\n",
    "    # Initialze h_0, c_0 with zeros\n",
    "    hidden = (\n",
    "      weight.new(self.n_layers, batch_size, self.hidden_dim)\n",
    "      .zero_()\n",
    "      .to(device),  # h_0\n",
    "      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "    )\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_loader,\n",
    "    learn_rate,\n",
    "    hidden_dim=256,\n",
    "    n_layers=2,\n",
    "    n_epochs=5,\n",
    "    model_type=\"GRU\",\n",
    "    print_every=100,\n",
    "):\n",
    "\n",
    "  input_dim = next(iter(train_loader))[0].shape[2]  # 5\n",
    "\n",
    "  # Batch generator (train_data, train_label)\n",
    "  # print(next(iter(train_loader))[0].shape, next(iter(train_loader))[1].shape) # torch.Size([1024, 90, 5]) torch.Size([1024, 1])\n",
    "\n",
    "  output_dim = 1\n",
    "\n",
    "  # Instantiating the models\n",
    "  if model_type == \"GRU\":\n",
    "    model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "  else:\n",
    "    model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "  model.to(device)\n",
    "\n",
    "  # Defining loss function and optimizer\n",
    "  criterion = nn.MSELoss()  # Mean Squared Error\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "  model.train()\n",
    "  print(\"Starting Training of {} model\".format(model_type))\n",
    "  epoch_times = []\n",
    "\n",
    "  # Start training loop\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    start_time = time.process_time()\n",
    "    h = model.init_hidden(batch_size)\n",
    "    avg_loss = 0.0\n",
    "    counter = 0\n",
    "    for x, label in train_loader:\n",
    "      counter += 1\n",
    "      if model_type == \"GRU\":\n",
    "        h = h.data\n",
    "      # Unpcak both h_0 and c_0\n",
    "      elif model_type == \"LSTM\":\n",
    "        h = tuple([e.data for e in h])\n",
    "\n",
    "      # Set the gradients to zero before starting to do backpropragation because\n",
    "      # PyTorch accumulates the gradients on subsequent backward passes\n",
    "      model.zero_grad()\n",
    "\n",
    "      out, h = model(x.to(device).float(), h)\n",
    "      loss = criterion(out, label.to(device).float())\n",
    "\n",
    "      # Perform backpropragation\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      avg_loss += loss.item()\n",
    "      if counter % print_every == 0:\n",
    "        print(f\"Epoch {epoch} - Step: {counter}/{len(train_loader)} - Average Loss for Epoch: {avg_loss/counter}\")\n",
    "    current_time = time.process_time()\n",
    "\n",
    "    print(f\"Epoch {epoch}/{n_epochs} Done, Total Loss: {avg_loss/len(train_loader)}\")\n",
    "\n",
    "    print(f\"Time Elapsed for Epoch: {current_time-start_time} seconds\")\n",
    "\n",
    "    epoch_times.append(current_time - start_time)\n",
    "\n",
    "  print(f\"Total Training Time: {sum(epoch_times)} seconds\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len = 90  # (timestamps)\n",
    "n_hidden = 256\n",
    "n_layers = 2\n",
    "n_epochs = 10  # Trocar para 200, pois se estabiliza\n",
    "print_every = 64\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of GRU model\n",
      "Epoch 1/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 87.796875 seconds\n",
      "Epoch 2/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 92.03125 seconds\n",
      "Epoch 3/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 89.515625 seconds\n",
      "Epoch 4/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 84.359375 seconds\n",
      "Epoch 5/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 91.328125 seconds\n",
      "Epoch 6/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 92.1875 seconds\n",
      "Epoch 7/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 82.734375 seconds\n",
      "Epoch 8/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 78.1875 seconds\n",
      "Epoch 9/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 79.140625 seconds\n",
      "Epoch 10/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 78.359375 seconds\n",
      "Total Training Time: 855.640625 seconds\n"
     ]
    }
   ],
   "source": [
    "gru_model = train(\n",
    "  train_loader,\n",
    "  learn_rate=lr,\n",
    "  hidden_dim=n_hidden,\n",
    "  n_layers=n_layers,\n",
    "  n_epochs=n_epochs,\n",
    "  model_type=\"GRU\",\n",
    "  print_every=print_every,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FALTA FILTRAR OS DADOS DE \"PODER PÚBLICO\" E \"REVENDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gru_model.state_dict(), \"./models/gru_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training of LSTM model\n",
      "Epoch 1/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 74.75 seconds\n",
      "Epoch 2/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 81.421875 seconds\n",
      "Epoch 3/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 72.96875 seconds\n",
      "Epoch 4/10 Done, Total Loss: nan\n",
      "Time Elapsed for Epoch: 80.53125 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lstm_model \u001b[39m=\u001b[39m train(\n\u001b[0;32m      2\u001b[0m   train_loader,\n\u001b[0;32m      3\u001b[0m   learn_rate\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m      4\u001b[0m   hidden_dim\u001b[39m=\u001b[39;49mn_hidden,\n\u001b[0;32m      5\u001b[0m   n_layers\u001b[39m=\u001b[39;49mn_layers,\n\u001b[0;32m      6\u001b[0m   n_epochs\u001b[39m=\u001b[39;49mn_epochs,\n\u001b[0;32m      7\u001b[0m   model_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mLSTM\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m   print_every\u001b[39m=\u001b[39;49mprint_every,\n\u001b[0;32m      9\u001b[0m )\n",
      "Cell \u001b[1;32mIn[10], line 55\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, learn_rate, hidden_dim, n_layers, n_epochs, model_type, print_every)\u001b[0m\n\u001b[0;32m     52\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, label\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     54\u001b[0m \u001b[39m# Perform backpropragation\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     56\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     58\u001b[0m avg_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    237\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    238\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    239\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    244\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 245\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\Pedro\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m--> 145\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[0;32m    146\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    147\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_model = train(\n",
    "  train_loader,\n",
    "  learn_rate=lr,\n",
    "  hidden_dim=n_hidden,\n",
    "  n_layers=n_layers,\n",
    "  n_epochs=n_epochs,\n",
    "  model_type=\"LSTM\",\n",
    "  print_every=print_every,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model.state_dict(), \"./models/lstm_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move device to cpu for evaluation to avoid GPU memory run\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 256\n",
    "input_dim = 5\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "gru_model = GRUNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "gru_model.load_state_dict(torch.load(\"./models/gru_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the appropriate device\n",
    "gru_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 256\n",
    "input_dim = 5\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "lstm_model = LSTMNet(input_dim, hidden_dim, output_dim, n_layers)\n",
    "lstm_model.load_state_dict(torch.load(\"./models/lstm_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAPE(outputs, targets):\n",
    "  sMAPE = (\n",
    "    100\n",
    "    / len(targets)\n",
    "    * np.sum(np.abs(outputs - targets) / (np.abs(outputs + targets)) / 2)\n",
    "  )\n",
    "  return sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y, label_scalers):\n",
    "  model.eval()\n",
    "  outputs = []\n",
    "  targets = []\n",
    "  start_time = time.process_time()\n",
    "  # get data of test data for each state\n",
    "  for file in test_x.keys():\n",
    "    inputs = torch.from_numpy(np.array(test_x[file]))\n",
    "    labels = torch.from_numpy(np.array(test_y[file]))\n",
    "\n",
    "    h = model.init_hidden(inputs.shape[0])\n",
    "\n",
    "    # predict outputs\n",
    "    with torch.no_grad():\n",
    "      out, h = model(inputs.to(device).float(), h)\n",
    "\n",
    "    outputs.append(\n",
    "      label_scalers[file]\n",
    "      .inverse_transform(out.cpu().detach().numpy())\n",
    "      .reshape(-1)\n",
    "    )\n",
    "\n",
    "    targets.append(label_scalers[file].inverse_transform(labels.numpy()).reshape(-1))\n",
    "\n",
    "  # Merge all files\n",
    "  concatenated_outputs = np.concatenate(outputs)\n",
    "  concatenated_targets = np.concatenate(targets)\n",
    "\n",
    "  print(f\"Evaluation Time: {time.process_time()-start_time}\")\n",
    "  print(f\"sMAPE: {round(sMAPE(concatenated_outputs, concatenated_targets), 3)}%\")\n",
    "\n",
    "  # list of of targets/outputs for each state\n",
    "  return outputs, targets, sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_outputs, targets, gru_sMAPE = evaluate(gru_model, test_x, test_y, label_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_outputs, targets, lstm_sMAPE = evaluate(lstm_model, test_x, test_y, label_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gru_outputs)  # list of predicted output file for each state (each element has a 1d array for that state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list = list(test_x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(gru_outputs[0][-100:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "plt.plot(lstm_outputs[0][-100:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "plt.plot(targets[0][-100:], color=\"b\", label=\"Actual\")\n",
    "plt.ylabel(\"Energy Consumption (MW)\")\n",
    "plt.title(f\"Energy Consumption for {states_list[0]} state\")\n",
    "plt.legend()\n",
    "\n",
    "# plt.subplot(2, 2, 2)\n",
    "# plt.plot(gru_outputs[1][-50:], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "# plt.plot(lstm_outputs[1][-50:], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "# plt.plot(targets[1][-50:], color=\"b\", label=\"Actual\")\n",
    "# plt.ylabel(\"Energy Consumption (MW)\")\n",
    "# plt.title(f\"Energy Consumption for {states_list[1]} state\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(2, 2, 3)\n",
    "# plt.plot(gru_outputs[2][:50], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "# plt.plot(lstm_outputs[2][:50], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "# plt.plot(targets[2][:50], color=\"b\", label=\"Actual\")\n",
    "# plt.ylabel(\"Energy Consumption (MW)\")\n",
    "# plt.title(f\"Energy Consumption for {states_list[2]} state\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(2, 2, 4)\n",
    "# plt.plot(gru_outputs[3][:100], \"-o\", color=\"g\", label=\"GRU Predictions\", markersize=2)\n",
    "# plt.plot(lstm_outputs[3][:100], \"-o\", color=\"r\", label=\"LSTM Predictions\", markersize=2)\n",
    "# plt.plot(targets[3][:100], color=\"b\", label=\"Actual\")\n",
    "# plt.title(f\"Energy Consumption for {states_list[3]} state\")\n",
    "# plt.ylabel(\"Energy Consumption (MW)\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
